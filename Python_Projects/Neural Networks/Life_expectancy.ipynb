{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m2,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,301</span> (8.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,301\u001b[0m (8.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,301</span> (8.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,301\u001b[0m (8.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = pd.read_csv(\"life_expectancy.csv\")\n",
    "dataset = dataset.drop([\"Country\"], axis = 1)\n",
    "\n",
    "# create labels and features\n",
    "labels = dataset.iloc[:, -1]\n",
    "features = dataset.iloc[:, 0:-1]\n",
    "\n",
    "#OHE\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "#split train and test data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#Normalize the data\n",
    "numerical_features = features.select_dtypes(include = [\"float64\", \"int\"])\n",
    "numerical_columns = numerical_features.columns\n",
    "\n",
    "ct = ColumnTransformer([(\"Std\", StandardScaler(), numerical_columns)], remainder = \"passthrough\")\n",
    "\n",
    "#fit the transformer \n",
    "features_train_scaled = ct.fit_transform(features_train)\n",
    "features_test_scaled = ct.transform(features_test)\n",
    "\n",
    "#fit the model\n",
    "my_model = Sequential()\n",
    "input = InputLayer(shape = (features.shape[1], ))\n",
    "my_model.add(input)\n",
    "my_model.add(Dense(100, activation = \"relu\"))\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362us/step - loss: 1478.0917 - mae: 20.8437\n",
      "Epoch 2/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365us/step - loss: 747.5928 - mae: 9.8596 \n",
      "Epoch 3/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - loss: 116.9718 - mae: 5.2747\n",
      "Epoch 4/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - loss: 42.6877 - mae: 4.5871\n",
      "Epoch 5/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347us/step - loss: 49.1623 - mae: 4.9706\n",
      "Epoch 6/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 32.9160 - mae: 4.1003\n",
      "Epoch 7/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 20.5571 - mae: 3.5019\n",
      "Epoch 8/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - loss: 28.1622 - mae: 3.8449\n",
      "Epoch 9/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - loss: 42.0427 - mae: 3.9239\n",
      "Epoch 10/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - loss: 22.6423 - mae: 3.6873\n",
      "Epoch 11/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 23.7580 - mae: 3.8156\n",
      "Epoch 12/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 21.0029 - mae: 3.5441\n",
      "Epoch 13/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - loss: 23.2610 - mae: 3.6408\n",
      "Epoch 14/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - loss: 22.0473 - mae: 3.7227\n",
      "Epoch 15/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - loss: 23.1721 - mae: 3.7165\n",
      "Epoch 16/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step - loss: 20.3966 - mae: 3.4511\n",
      "Epoch 17/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347us/step - loss: 22.6324 - mae: 3.6828\n",
      "Epoch 18/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - loss: 23.8834 - mae: 3.7366\n",
      "Epoch 19/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step - loss: 21.6447 - mae: 3.6267\n",
      "Epoch 20/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - loss: 21.9559 - mae: 3.5914\n",
      "Epoch 21/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347us/step - loss: 23.6537 - mae: 3.8024\n",
      "Epoch 22/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - loss: 24.0583 - mae: 3.7103\n",
      "Epoch 23/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371us/step - loss: 24.4668 - mae: 3.8184\n",
      "Epoch 24/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - loss: 22.9613 - mae: 3.6930\n",
      "Epoch 25/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - loss: 22.3118 - mae: 3.6788\n",
      "Epoch 26/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - loss: 21.2215 - mae: 3.6278\n",
      "Epoch 27/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - loss: 21.5190 - mae: 3.6616\n",
      "Epoch 28/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 22.7481 - mae: 3.6652\n",
      "Epoch 29/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 24.2231 - mae: 3.8229\n",
      "Epoch 30/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - loss: 21.8035 - mae: 3.5882\n",
      "Epoch 31/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324us/step - loss: 26.8763 - mae: 3.9602\n",
      "Epoch 32/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359us/step - loss: 22.3592 - mae: 3.6873\n",
      "Epoch 33/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - loss: 23.0865 - mae: 3.7496\n",
      "Epoch 34/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - loss: 21.6161 - mae: 3.5713\n",
      "Epoch 35/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - loss: 22.9069 - mae: 3.6431\n",
      "Epoch 36/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - loss: 22.7366 - mae: 3.6190\n",
      "Epoch 37/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324us/step - loss: 19.8726 - mae: 3.4330\n",
      "Epoch 38/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357us/step - loss: 19.5855 - mae: 3.3845\n",
      "Epoch 39/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step - loss: 20.6435 - mae: 3.5380\n",
      "Epoch 40/40\n",
      "\u001b[1m2056/2056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - loss: 19.1817 - mae: 3.4157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x193cf08acc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add optimizer instance\n",
    "opt = Adam(learning_rate = 0.1)\n",
    "\n",
    "#compile the model \n",
    "my_model.compile(loss = \"mse\", metrics = [\"mae\"], optimizer = opt)\n",
    "\n",
    "#fit the model \n",
    "my_model.fit(features_train_scaled, labels_train, epochs = 40, batch_size = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model mean squared error is: 26.332378387451172\n",
      "The model mean absolute error is 3.322197914123535\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model \n",
    "res_mse, res_mae = my_model.evaluate(features_test_scaled, labels_test, verbose = 0)\n",
    "print(f\"The model mean squared error is: {res_mse}\")\n",
    "print(f\"The model mean absolute error is {res_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
